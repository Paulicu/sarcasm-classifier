\section{Results}
In this section, I will present the performance of both the machine learning and deep learning models on the sarcasm detection task. The evaluation metrics include accuracy, F1 score, 
recall, and precision. In addition, confusion matrices provide further insight into each model's performance by detailing the distribution of true positives, true negatives, 
false positives, and false negatives.

\subsection{Machine Learning Models Results}

Table \ref{Table_1} summarizes the performance metrics for the four machine learning models that were tested using both TF-IDF and Bag-of-Words (BoW) representations.

\begin{table}
    \caption{Machine Learning Models Results}
    \label{Table_1}
    \begin{tabular}{ccccc}
        \toprule
            \textbf{Model} & \textbf{Accuracy (\%)} & \textbf{F1 Score (\%)} & \textbf{Recall (\%)} & \textbf{Precision (\%)} \\
        \midrule
            Logistic Regression (TF-IDF)  & 71.9 & 70.7 & 67.7 & 73.9 \\
            Ridge Regression (TF-IDF)     & 71.5 & 70.5 & 68.2 & 73.0 \\
            Logistic Regression (BoW)     & 71.9 & 70.4 & 66.9 & 74.3 \\
            Ridge Regression (BoW)        & 71.2 & 69.5 & 65.7 & 73.8 \\
         \bottomrule
    \end{tabular}
\end{table}

Logistic Regression model with TF-IDF achieved an accuracy of 71.9\% and an F1 score of 70.7\%. The confusion matrix reveals 273,531 true positives and 307,988 true negatives, 
with 96,334 false positives and 130,741 false negatives. While the model demonstrates a reasonably strong performance overall, the relatively high number of false negatives suggests that it sometimes 
fails to detect sarcasm, misclassifying sarcastic comments as normal.

Ridge Regression with TF-IDF achieved slightly lower accuracy at 71.5\% and an F1 score of 70.5\%. This model recorded 275,560 true positives and 302,802 true negatives, 
with 101,520 false positives and 128,712 false negatives. Compared to Logistic Regression (TF-IDF), it is marginally more aggressive in predicting sarcasm, as indicated by the higher 
false positive count, although it does slightly better in terms of capturing sarcastic instances (fewer false negatives).

When using a BoW representation, Logistic Regression obtained an accuracy of 71.9\% and an F1 score of 70.4\%. The confusion matrix shows 270,556 true positives and 310,948 true negatives, 
with 93,374 false positives and 133,716 false negatives. This model correctly classifies a higher number of normal comments, as indicated by the increased true negative count and reduced 
false positives. However, this comes at the cost of a higher number of false negatives, meaning that it misses a greater number of sarcastic comments.

Ridge Regression with BoW achieved an accuracy of 71.2\% and an F1 score of 69.5\%. Its confusion matrix reveals 265,506 true positives and 310,275 true negatives, along with 
94,047 false positives and the highest number of false negatives at 138,766. This model struggles most with detecting sarcastic comments, as evidenced by its high false negative count, 
even though it performs well in correctly identifying normal comments.

Overall, TF-IDF-based models provide a better balance between false positives and false negatives compared to their BoW counterparts. Among these, Logistic Regression with TF-IDF offers 
the best trade-off, achieving high accuracy while minimizing misclassifications. This model was trained on the full dataset and obtained an accuracy of 72.23\%. The confusion matrices 
for the models are available in Figure \ref{Fig_4}.

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{img/conf_matrix.png}
    \caption{Confusion Matrices}
    \label{Fig_4}
\end{figure}

\subsection{Deep Learning Models Results}

The LSTM model using GloVe embeddings achieved an accuracy of 71.02\% with an F1 score of 70.78\%. The performance indicates that the model effectively leverages the semantic information provided 
by the GloVe vectors, although its performance is comparable to the traditional machine learning methods. I believe that the low performance is due to the Glove embeddings not being trained in 
the specific context of social media, and also due to its low embedding dimensions. For future improvement, I would recommend using the glove embeddings trained specifically on Twitter data, which 
may resemble the dataset a bit more. Also, if enough computational resources are present, increasing the number of embeddings might increase model performance.

The LSTM model using Word2Vec embeddings outperformed its GloVe counterpart, reaching an accuracy of 72.64\% and an F1 score of 72.55\%. This suggests that Word2Vec embeddings better capture the 
nuances required for sarcasm detection in the dataset. The improved performance metrics indicate that the Word2Vec-based model is more effective at discerning the subtle differences between sarcastic 
and normal comments.

The summary of these results are displayed in Table \ref{Table_2}.

While this architecture is effective for large datasets, further improvements can enhance its performance. Adding a Bidirectional LSTM layer would allow the model to process the input sequence in both 
forward and backward directions. This approach captures context from both sides, producing an output shape of (None, 128) by concatenating the outputs of both directions.

Another potential enhancement is the inclusion of a GlobalMaxPooling1D Layer. This layer reduces the sequence dimension by retaining only the maximum value for each feature map, helping to highlight 
the most prominent features while reducing computational complexity.

Additional improvements include Batch Normalization, which normalizes layer activations to accelerate convergence and improve generalization, and increasing the number of LSTM units from 64 to 128. 
Stacking multiple LSTM layers can further enhance the model's capacity to learn complex patterns, though it increases the risk of overfitting and training time.

I explored all these architectures before deciding to the final layers, but because of the high training times and computational resource usage, I decided to stick with the simple architecture. 
Most of my tests performed on these advanced layers were starting with low performance, but getting better in time. I believe that with enough computational power, the accuracy of the models can 
easily go past 80\%.

\begin{table}
    \caption{LSTM Models Results}
    \label{Table_2}
    \begin{tabular}{ccccc}
        \toprule
            \textbf{Model} & \textbf{Accuracy (\%)} & \textbf{F1 Score (\%)} & \textbf{Recall (\%)} & \textbf{Precision (\%)} \\
        \midrule
            LSTM GloVe     & 71.02 & 70.78 & 71.02 & 71.74 \\
            LSTM Word2Vec  & 72.64 & 72.55 & 72.64 & 72.94 \\
        \bottomrule
    \end{tabular}
\end{table}